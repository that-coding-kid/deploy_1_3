{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6QaxmuVi9o5",
        "outputId": "6faa6049-1e5e-4682-9340-847afdddbc74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat May 18 13:30:59 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3050 ...    Off | 00000000:01:00.0  On |                  N/A |\n",
            "| N/A   58C    P0              10W /  80W |    617MiB /  4096MiB |     19%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      3120      G   /usr/lib/xorg/Xorg                          226MiB |\n",
            "|    0   N/A  N/A      3267      G   /usr/bin/gnome-shell                         56MiB |\n",
            "|    0   N/A  N/A      5914      G   ...seed-version=20240513-040113.413000       28MiB |\n",
            "|    0   N/A  N/A      8800      G   ...ures=SpareRendererForSitePerProcess       32MiB |\n",
            "|    0   N/A  N/A      8993      G   ...irefox/3836/usr/lib/firefox/firefox      139MiB |\n",
            "|    0   N/A  N/A     13673      G   ...erProcess --variations-seed-version      119MiB |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDe6RKo1kc3v",
        "outputId": "4dfe8b0a-1e00-4f66-83c0-cc624ae1da76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/dev/Downloads\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMPMf04lkjqw",
        "outputId": "d3f940f1-45c5-4356-a22e-4e7dba43a7c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/dev/Downloads\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dev/Documents/GitHub/deploy/venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cRGlhA2AksWw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/dev/Downloads/clip3.mp4\n"
          ]
        }
      ],
      "source": [
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt\n",
        "SOURCE_VIDEO_PATH = f\"{HOME}/clip3.mp4\"\n",
        "print(SOURCE_VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL7aMCoklIu3",
        "outputId": "a4b397a1-bc2e-47bd-db13-e6896883aa9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.10  Python-3.10.14 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
            "Setup complete  (12 CPUs, 15.7 GB RAM, 424.1/454.9 GB disk)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip uninstall torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIfF7xDFlz93",
        "outputId": "5ad87593-c9f2-4577-c1da-00988789c126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "# !git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
        "!pip install -q loguru lap thop\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "byHZZSkBmXeE"
      },
      "outputs": [],
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X-VtqiPmwSY",
        "outputId": "55a2af15-f0fb-490e-c166-a3bbd5207420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "supervision.__version__: 0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RxZeiUtwmynR"
      },
      "outputs": [],
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Kqc9B_uonCQ-"
      },
      "outputs": [],
      "source": [
        "# settings\n",
        "MODEL = \"yolov8x.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG-8_psFnHkO",
        "outputId": "4d140242-c968-4e51-c8e8-b426ce750ee8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fusing... \n",
            "YOLOv8x summary: 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# device: str = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "# print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep9C92KPnJpp",
        "outputId": "ae16b424-1777-49c2-a814-54d01ba270c9"
      },
      "outputs": [],
      "source": [
        "# %cd {HOME}\n",
        "# !yolo task=detect mode=predict model=yolov8x.pt conf=0.25 source={f\"helloWorld.mp4\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "CLASS_NAMES_DICT = model.model.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'person',\n",
              " 1: 'bicycle',\n",
              " 2: 'car',\n",
              " 3: 'motorcycle',\n",
              " 4: 'airplane',\n",
              " 5: 'bus',\n",
              " 6: 'train',\n",
              " 7: 'truck',\n",
              " 8: 'boat',\n",
              " 9: 'traffic light',\n",
              " 10: 'fire hydrant',\n",
              " 11: 'stop sign',\n",
              " 12: 'parking meter',\n",
              " 13: 'bench',\n",
              " 14: 'bird',\n",
              " 15: 'cat',\n",
              " 16: 'dog',\n",
              " 17: 'horse',\n",
              " 18: 'sheep',\n",
              " 19: 'cow',\n",
              " 20: 'elephant',\n",
              " 21: 'bear',\n",
              " 22: 'zebra',\n",
              " 23: 'giraffe',\n",
              " 24: 'backpack',\n",
              " 25: 'umbrella',\n",
              " 26: 'handbag',\n",
              " 27: 'tie',\n",
              " 28: 'suitcase',\n",
              " 29: 'frisbee',\n",
              " 30: 'skis',\n",
              " 31: 'snowboard',\n",
              " 32: 'sports ball',\n",
              " 33: 'kite',\n",
              " 34: 'baseball bat',\n",
              " 35: 'baseball glove',\n",
              " 36: 'skateboard',\n",
              " 37: 'surfboard',\n",
              " 38: 'tennis racket',\n",
              " 39: 'bottle',\n",
              " 40: 'wine glass',\n",
              " 41: 'cup',\n",
              " 42: 'fork',\n",
              " 43: 'knife',\n",
              " 44: 'spoon',\n",
              " 45: 'bowl',\n",
              " 46: 'banana',\n",
              " 47: 'apple',\n",
              " 48: 'sandwich',\n",
              " 49: 'orange',\n",
              " 50: 'broccoli',\n",
              " 51: 'carrot',\n",
              " 52: 'hot dog',\n",
              " 53: 'pizza',\n",
              " 54: 'donut',\n",
              " 55: 'cake',\n",
              " 56: 'chair',\n",
              " 57: 'couch',\n",
              " 58: 'potted plant',\n",
              " 59: 'bed',\n",
              " 60: 'dining table',\n",
              " 61: 'toilet',\n",
              " 62: 'tv',\n",
              " 63: 'laptop',\n",
              " 64: 'mouse',\n",
              " 65: 'remote',\n",
              " 66: 'keyboard',\n",
              " 67: 'cell phone',\n",
              " 68: 'microwave',\n",
              " 69: 'oven',\n",
              " 70: 'toaster',\n",
              " 71: 'sink',\n",
              " 72: 'refrigerator',\n",
              " 73: 'book',\n",
              " 74: 'clock',\n",
              " 75: 'vase',\n",
              " 76: 'scissors',\n",
              " 77: 'teddy bear',\n",
              " 78: 'hair drier',\n",
              " 79: 'toothbrush'}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CLASS_NAMES_DICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dell\\Desktop\\all_files\\Datathon\\Problem Statement - 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dell\\Desktop\\all_files\\Datathon\\.conda\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "TARGET_VIDEO_PATH =  f\"{HOME}/analyzed.mp4\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\desktop\\all_files\\datathon\\.conda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\desktop\\all_files\\datathon\\.conda\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip3 install ipywidgets --user\n",
        "# # \n",
        "!pip install scikit-learn --upgrade --user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "LINE_START = Point(820,180)\n",
        "LINE_END = Point(1600,180)\n",
        "LINE_START2 = Point(1150,180)\n",
        "LINE_END2 = Point(1150,710)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZhJ_fITQS5L",
        "outputId": "deb31c7c-2a56-4382-f147-4278a9c51daf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e2bf2f5c1b54833980b11d8eb0c52c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1594 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "bytetracker = BYTETracker(BYTETrackerArgs())\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(),thickness=2,text_thickness= 1,text_scale=0.5)\n",
        "box_annotator2 = BoxAnnotator(color=ColorPalette(),thickness=6,text_thickness= 6,text_scale=1)\n",
        "\n",
        "linecounter = LineCounter(start= LINE_START,end= LINE_END)\n",
        "linecounter2 = LineCounter(start= LINE_START2,end= LINE_END2)\n",
        "lineAnnotator = LineCounterAnnotator(thickness=2,text_thickness=1,text_scale=0.5)\n",
        "# start, end = Point(x=0, y=1080), Point(x=3840, y=1080)\n",
        "# line_zone = LineZone(start=start, end=end)\n",
        "frameCount = 0\n",
        "prev_count = 0\n",
        "threshold = 4\n",
        "with VideoSink(TARGET_VIDEO_PATH,video_info) as sink:\n",
        "    for frame in tqdm(generator,total=video_info.total_frames):\n",
        "        frameCount+=1\n",
        "        results = model(frame)[0]\n",
        "        indices = []\n",
        "        for k,i in enumerate(results.boxes.cls.cpu().numpy().astype(int)):\n",
        "            if (i>0 and i<11):\n",
        "                indices.append(k)\n",
        "            else:\n",
        "                pass\n",
        "        indices = np.array(indices)\n",
        "        detections = Detections(\n",
        "            xyxy = results.boxes.xyxy.cpu().numpy()[indices],\n",
        "            confidence= results.boxes.conf.cpu().numpy()[indices],\n",
        "            class_id = results.boxes.cls.cpu().numpy().astype(int)[indices]\n",
        "        )\n",
        "\n",
        "        tracks = bytetracker.update(\n",
        "            output_results = detections2boxes(detections=detections),\n",
        "            img_info = frame.shape,\n",
        "            img_size = frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections,tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {condfidence:0.2f}\"\n",
        "            for _,condfidence,class_id,tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "        if (frameCount%120 == 0):\n",
        "            count_increase = max(linecounter2.in_count,linecounter2.out_count)-prev_count\n",
        "            if (count_increase >= threshold):\n",
        "                category = [1]\n",
        "                labels2 = [\"Good\"]\n",
        "            else:\n",
        "                category = [0]\n",
        "                labels2 = [\"Bad\"]\n",
        "            prev_count = max(linecounter2.in_count,linecounter2.out_count)\n",
        "        \n",
        "        detections2= Detections(\n",
        "            xyxy= np.array([[100,100,1750,1000]]),\n",
        "            confidence= np.array([1.0]),\n",
        "            class_id=np.array(category)\n",
        "        )\n",
        "        frame = box_annotator.annotate(frame=frame,detections=detections,labels = labels)\n",
        "        frame = box_annotator2.annotate(frame=frame,detections=detections2,labels = labels2)\n",
        "\n",
        "        # show_frame_in_notebook(frame,(16,16))\n",
        "        linecounter.update(detections=detections)\n",
        "        lineAnnotator.annotate(frame=frame,line_counter=linecounter)\n",
        "        # crossed_in, crossed_out = line_zone.trigger(detections)\n",
        "\n",
        "        linecounter2.update(detections=detections)\n",
        "        lineAnnotator.annotate(frame=frame,line_counter=linecounter2)\n",
        "\n",
        "        sink.write_frame(frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "linecounter2.out_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "gcb = np.array([1,2,3,4,5,6,7,8,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'supervision.geometry.dataclasses'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msupervision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(supervision\u001b[38;5;241m.\u001b[39mgeometry))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msupervision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclasses\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(supervision\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mdataclasses))\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'supervision.geometry.dataclasses'"
          ]
        }
      ],
      "source": [
        "import supervision.geometry\n",
        "print(dir(supervision.geometry))\n",
        "\n",
        "import supervision.geometry.dataclasses\n",
        "print(dir(supervision.geometry.dataclasses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n",
            "['Optional', 'Tuple', 'VideoInfo', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'annotations', 'cv2', 'dataclass']\n"
          ]
        }
      ],
      "source": [
        "import supervision.video\n",
        "print(dir(supervision.video))\n",
        "\n",
        "import supervision.video.dataclasses\n",
        "print(dir(supervision.video.dataclasses))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n",
            "['Point', 'Rect', 'Tuple', 'Vector', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'annotations', 'dataclass']\n"
          ]
        }
      ],
      "source": [
        "import supervision.geometry\n",
        "print(dir(supervision.geometry))\n",
        "\n",
        "import supervision.geometry.dataclasses\n",
        "print(dir(supervision.geometry.dataclasses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'color']\n",
            "['Color', 'ColorPalette', 'DEFAULT_COLOR_PALETTE', 'List', 'Tuple', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_validate_color_hex', 'annotations', 'dataclass', 'field']\n"
          ]
        }
      ],
      "source": [
        "import supervision.draw\n",
        "print(dir(supervision.draw))\n",
        "\n",
        "import supervision.draw.color\n",
        "print(dir(supervision.draw.color))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
